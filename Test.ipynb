{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec, word2vec\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from analysis import *\n",
    "from tqdm import tqdm\n",
    "file_path = './data/docs_jsonl_space_jamo.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files: 100%|██████████| 616311/616311 [00:03<00:00, 157485.01it/s]\n"
     ]
    }
   ],
   "source": [
    "app_id_list, app_name_list, cate_list, rating_list, docs = read_jsonl(file_path, key_ma=False, \n",
    "                                                                      only_ma=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stopwords(docs, tokenizer):\n",
    "    new_docs = []\n",
    "    for doc in tqdm(docs, desc='doing', total=len(docs)):\n",
    "        remove_list = list(set([ma[0] for ma in tokenizer.pos(doc) if ma[1] in ['SF', 'SC', 'SSO', 'SSC', 'SC', 'SY']]))\n",
    "        for r in remove_list:\n",
    "            doc = doc.replace(r, '').replace('   ', ' ').replace('  ', ' ')\n",
    "        new_docs.append(doc)\n",
    "        \n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "doing: 100%|██████████| 616311/616311 [01:09<00:00, 8857.46it/s] \n"
     ]
    }
   ],
   "source": [
    "new_docs = stopwords(docs, mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path2 = './data/docs_jsonl_remove_S.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving documents: 100%|██████████| 616311/616311 [00:06<00:00, 95731.89it/s] \n"
     ]
    }
   ],
   "source": [
    "save_jsonl(file_path2, app_id_list, app_name_list, cate_list, rating_list, new_docs, key_ma=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files: 100%|██████████| 616311/616311 [01:06<00:00, 9313.80it/s] \n"
     ]
    }
   ],
   "source": [
    "file_path = './data/docs_jsonl_ma_mecab.txt'\n",
    "app_id_list, app_name_list, cate_list, rating_list, docs = read_jsonl(file_path, key_ma=True, \n",
    "                                                                      only_ma=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_morphs = []\n",
    "for doc in docs:\n",
    "    docs_morphs.append([ma[0] for ma in doc])\n",
    "\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_docs_morphs = [TaggedDocument(d, [r]) for d, r in zip(docs_morphs, app_id_list)]\n",
    "tagged_docs_morphs = [TaggedDocument(d, [r]) for d, r in zip(docs, app_id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/docs_mecab_noma.txt', 'w', encoding='utf-8') as file:\n",
    "    for doc in docs_morphs:\n",
    "        print(' '.join(doc), file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText\n",
    "\n",
    "등록되지 않은 데이터를 처리하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ft_model = FastText.load_fasttext_format('./data/gensim_model/fasttext/mecab_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복음 exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('내려요', 0.4601520299911499),\n",
       " ('여서', 0.36375096440315247),\n",
       " ('으니까', 0.3515215218067169),\n",
       " ('튕김현상', 0.3389400243759155),\n",
       " ('당합니다', 0.3371686339378357),\n",
       " ('들으면', 0.3327321708202362),\n",
       " ('질립니다', 0.32110482454299927),\n",
       " ('올라서', 0.319903165102005),\n",
       " ('라이트', 0.31211328506469727),\n",
       " ('터집니다', 0.3097568154335022)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word = '복음'\n",
    "print('{0} exists'.format(test_word)) if test_word in ft_model.wv.index2word else print('{0} not exists'.format(test_word))\n",
    "ft_model.most_similar(negative=[test_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = './data/docs_jsonl_ma_mecab.txt'\n",
    "app_id_list, app_name_list, cate_list, rating_list, docs = read_jsonl(file_path, key_ma=True, \n",
    "                                                                      only_ma=False)\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_docs_morphs = [TaggedDocument(d, [r]) for d, r in zip(docs, app_id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "tf_idf = gensim.models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
